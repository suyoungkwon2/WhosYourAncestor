"""
Female ë°ì´í„°ë§Œ ì‚¬ìš©í•œ AI ëª¨ë¸ í•™ìŠµ
ë†’ì€ ì •í™•ë„ë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ë‹¨ê³„ì  í•™ìŠµ
"""

import os
import json
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import gc

def setup_tensorflow():
    """TensorFlow í™˜ê²½ ì„¤ì •"""
    print("ğŸš€ Female ì „ìš© AI í•™ìŠµ ì‹œì‘")
    print("=" * 50)
    print("ğŸ”§ TensorFlow í™˜ê²½ ì„¤ì • ì¤‘...")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    
    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("âœ… GPU ë©”ëª¨ë¦¬ ì¦ê°€ ì„¤ì • ì™„ë£Œ")
        except RuntimeError as e:
            print(f"âš ï¸ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
    
    print(f"TensorFlow ë²„ì „: {tf.__version__}")
    print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {len(tf.config.list_physical_devices('GPU'))}")

def load_female_data():
    """Female ë°ì´í„°ë§Œ ë¡œë“œ"""
    print("ğŸ“‚ Female ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ê°€ëŠ¥í•œ ë°ì´í„° ê²½ë¡œë“¤
    possible_paths = [
        "/content/dataset",
        "/content/drive/MyDrive/WhosYourAncestor/data",
        "/content/drive/MyDrive/WhosYourAncestor",
        "/content/WhosYourAncestor/data",
        "/content/data",
        "/content"
    ]
    
    data_dir = None
    for path in possible_paths:
        if os.path.exists(path):
            print(f"âœ… ë°ì´í„° ê²½ë¡œ ë°œê²¬: {path}")
            data_dir = path
            break
    
    if data_dir is None:
        print("âŒ ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ ë‚´ìš©:")
        print(os.listdir("/content"))
        if os.path.exists("/content/drive/MyDrive"):
            print("ğŸ“ Google Drive ë‚´ìš©:")
            print(os.listdir("/content/drive/MyDrive"))
        raise FileNotFoundError("ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # dataset í´ë” ë‚´ìš© í™•ì¸
    print(f"ğŸ“ {data_dir} í´ë” ë‚´ìš©:")
    print(os.listdir(data_dir))
    
    female_dir = os.path.join(data_dir, "female")
    
    if not os.path.exists(female_dir):
        print(f"âŒ Female í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {female_dir}")
        print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ í´ë”ë“¤:")
        print(os.listdir(data_dir))
        raise FileNotFoundError(f"Female í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {female_dir}")
    
    images = []
    labels = []
    label_names = []
    
    # Female í´ë”ì˜ êµ­ê°€ë³„ ë°ì´í„° ìˆ˜ì§‘
    countries = [d for d in os.listdir(female_dir) if os.path.isdir(os.path.join(female_dir, d))]
    countries.sort()
    
    print(f"ğŸ“Š ë°œê²¬ëœ êµ­ê°€: {len(countries)}ê°œ")
    print(f"ğŸ“Š êµ­ê°€ ëª©ë¡: {countries}")
    
    for country in countries:
        country_path = os.path.join(female_dir, country)
        files = [f for f in os.listdir(country_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        print(f"ğŸ‘© {country} ì²˜ë¦¬ ì¤‘... ({len(files)}ê°œ)")
        
        for file in files:
            try:
                image_path = os.path.join(country_path, file)
                img = Image.open(image_path).convert('RGB')
                img = img.resize((224, 224))
                img_array = np.array(img) / 255.0
                
                images.append(img_array)
                labels.append(country)
                label_names.append(f"{country}_female")
                
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file} - {e}")
    
    return np.array(images), np.array(labels), label_names

def create_improved_model(num_classes):
    """ê°œì„ ëœ ëª¨ë¸ ìƒì„±"""
    print("ğŸ—ï¸ ê°œì„ ëœ ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # EfficientNetB0 ê¸°ë°˜ ì „ì´í•™ìŠµ
    base_model = tf.keras.applications.EfficientNetB0(
        include_top=False,
        weights='imagenet',
        input_shape=(224, 224, 3)
    )
    
    # ë² ì´ìŠ¤ ëª¨ë¸ ë™ê²°
    base_model.trainable = False
    
    model = tf.keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.5),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.2),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    # ì»´íŒŒì¼
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    return model

def train_model(model, X_train, y_train, X_val, y_val, num_classes):
    """ëª¨ë¸ í•™ìŠµ"""
    print("ğŸ¯ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    # ì½œë°± ì„¤ì •
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7
        ),
        tf.keras.callbacks.ModelCheckpoint(
            'best_female_model.h5',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # ë°ì´í„° ì¦ê°•
    data_augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
        layers.RandomBrightness(0.2),
        layers.RandomContrast(0.2),
    ])
    
    # í•™ìŠµ
    history = model.fit(
        data_augmentation(X_train),
        y_train,
        validation_data=(X_val, y_val),
        epochs=100,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    return history

def evaluate_model(model, X_test, y_test, label_encoder):
    """ëª¨ë¸ í‰ê°€"""
    print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
    
    # ì˜ˆì¸¡
    predictions = model.predict(X_test)
    y_pred = np.argmax(predictions, axis=1)
    
    # ì •í™•ë„ ê³„ì‚°
    accuracy = np.mean(y_pred == y_test)
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    from sklearn.metrics import classification_report
    class_names = label_encoder.classes_
    print("\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì •í™•ë„:")
    print(classification_report(y_test, y_pred, target_names=class_names))
    
    return accuracy

def save_model_for_web(model, label_encoder, num_classes):
    """ì›¹ ë°°í¬ìš© ëª¨ë¸ ì €ì¥"""
    print("ğŸŒ ì›¹ ë°°í¬ìš© ëª¨ë¸ ì €ì¥ ì¤‘...")
    
    # ëª¨ë¸ ì •ë³´ ì €ì¥
    model_info = {
        "labels": [f"{label}_female" for label in label_encoder.classes_],
        "input_shape": [224, 224, 3],
        "num_classes": num_classes
    }
    
    with open('model_info_female.json', 'w') as f:
        json.dump(model_info, f, indent=2)
    
    # TensorFlow.js ëª¨ë¸ ë³€í™˜
    import tensorflowjs as tfjs
    tfjs.converters.save_keras_model(model, 'web_model_female')
    
    print("âœ… ì›¹ ë°°í¬ìš© ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

def plot_training_history(history):
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì •í™•ë„
    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title('Model Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True)
    
    # ì†ì‹¤
    ax2.plot(history.history['loss'], label='Training Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title('Model Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('female_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # TensorFlow ì„¤ì •
    setup_tensorflow()
    
    # ë°ì´í„° ë¡œë“œ
    images, labels, label_names = load_female_data()
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(images)}ê°œ")
    print(f"ğŸ“Š ë°ì´í„° í˜•íƒœ: {images.shape}")
    print(f"ğŸ·ï¸ ë¼ë²¨ ê°œìˆ˜: {len(set(labels))}")
    
    # ë¼ë²¨ ì¸ì½”ë”©
    label_encoder = LabelEncoder()
    labels_encoded = label_encoder.fit_transform(labels)
    num_classes = len(label_encoder.classes_)
    
    print(f"ğŸ“ˆ êµ­ê°€ë³„ ë°ì´í„° ë¶„í¬:")
    for i, country in enumerate(label_encoder.classes_):
        count = np.sum(labels_encoded == i)
        print(f"  {country}: {count}ê°œ")
    
    # ë°ì´í„° ë¶„í• 
    X_train, X_temp, y_train, y_temp = train_test_split(
        images, labels_encoded, test_size=0.3, random_state=42, stratify=labels_encoded
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(X_val)}ê°œ")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
    
    # ëª¨ë¸ ìƒì„±
    model = create_improved_model(num_classes)
    
    # ëª¨ë¸ í•™ìŠµ
    history = train_model(model, X_train, y_train, X_val, y_val, num_classes)
    
    # ëª¨ë¸ í‰ê°€
    accuracy = evaluate_model(model, X_test, y_test, label_encoder)
    
    # ì›¹ ë°°í¬ìš© ëª¨ë¸ ì €ì¥
    save_model_for_web(model, label_encoder, num_classes)
    
    # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
    plot_training_history(history)
    
    print("\nğŸ‰ Female ì „ìš© ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… ì •í™•ë„: {accuracy*100:.2f}%")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("  - best_female_model.h5 (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)")
    print("  - web_model_female/ (TensorFlow.js ëª¨ë¸)")
    print("  - model_info_female.json (ëª¨ë¸ ì •ë³´)")
    print("  - female_training_history.png (í•™ìŠµ ê·¸ë˜í”„)")

if __name__ == "__main__":
    main() 