#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Colab ë¹ ë¥¸ ì‹œì‘ í¬ë¡¤ëŸ¬
ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ìš© ìŠ¤í¬ë¦½íŠ¸
"""

import os
import time
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from PIL import Image
import io

def setup_colab():
    """Colab í™˜ê²½ ì„¤ì •"""
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    os.system("pip install selenium pillow requests")
    
    # Chrome ë“œë¼ì´ë²„ ì„¤ì¹˜
    os.system("apt-get update")
    os.system("apt-get install -y chromium-chromedriver")
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['PATH'] += ':/usr/bin/chromedriver'
    
    print("âœ… Colab í™˜ê²½ ì„¤ì • ì™„ë£Œ")

def create_crawler():
    """í¬ë¡¤ëŸ¬ ìƒì„±"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def download_images(driver, query, save_dir, max_images=20):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    search_url = f"https://www.google.com/search?q={query}&tbm=isch"
    
    try:
        driver.get(search_url)
        time.sleep(2)
        
        # ì´ë¯¸ì§€ ìš”ì†Œ ì°¾ê¸°
        img_elements = driver.find_elements(By.CSS_SELECTOR, "img.rg_i")
        downloaded = 0
        
        os.makedirs(save_dir, exist_ok=True)
        
        for i, img in enumerate(img_elements[:max_images]):
            try:
                # ì´ë¯¸ì§€ í´ë¦­
                img.click()
                time.sleep(1)
                
                # í° ì´ë¯¸ì§€ ì°¾ê¸°
                large_img = WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "img.r48jcc"))
                )
                
                src = large_img.get_attribute('src')
                if src and src.startswith('http'):
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    
                    response = requests.get(src, headers=headers, timeout=10)
                    if response.status_code == 200:
                        # ì´ë¯¸ì§€ ì²˜ë¦¬
                        img_data = Image.open(io.BytesIO(response.content))
                        img_data = img_data.resize((224, 224), Image.Resampling.LANCZOS)
                        
                        # ì €ì¥
                        filename = f"{query.replace(' ', '_')}_{i+1:03d}.jpg"
                        save_path = os.path.join(save_dir, filename)
                        img_data.save(save_path, 'JPEG', quality=85)
                        
                        downloaded += 1
                        print(f"âœ… ë‹¤ìš´ë¡œë“œ: {filename}")
                
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        return downloaded
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return 0

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸš€ Colab í¬ë¡¤ëŸ¬ ì‹œì‘")
    
    # í™˜ê²½ ì„¤ì •
    setup_colab()
    
    # í¬ë¡¤ëŸ¬ ìƒì„±
    driver = create_crawler()
    
    try:
        # í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘
        test_queries = [
            "japanese female celebrity profile picture",
            "korean male celebrity profile picture"
        ]
        
        base_path = "/content/dataset"
        total_downloaded = 0
        
        for query in test_queries:
            print(f"\nğŸ“¸ {query} ìˆ˜ì§‘ ì¤‘...")
            
            # ì €ì¥ ê²½ë¡œ ì„¤ì •
            save_dir = os.path.join(base_path, query.split()[1], query.split()[0])
            
            downloaded = download_images(driver, query, save_dir, max_images=10)
            total_downloaded += downloaded
            
            print(f"âœ… {query}: {downloaded}ì¥ ìˆ˜ì§‘ ì™„ë£Œ")
            time.sleep(3)
        
        print(f"\nğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {total_downloaded}ì¥")
        
        # ê²°ê³¼ í™•ì¸
        if os.path.exists(base_path):
            print("\nğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°:")
            for root, dirs, files in os.walk(base_path):
                if files:
                    print(f"  {root}: {len(files)}ê°œ íŒŒì¼")
        
    finally:
        driver.quit()
        print("âœ… í¬ë¡¤ëŸ¬ ì¢…ë£Œ")

if __name__ == "__main__":
    main() 